import streamlit as st
import whisper
import tempfile
from st_audiorec import st_audiorec
import scipy.io.wavfile
import numpy as np
import os

st.title("\ud83c\udfa4 éŒ²éŸ³\uff0bè©±è€…åˆ†é›¢\uff0bæ–‡å­—èµ·ã“ã— (ãƒ–ãƒ©ã‚¦ã‚¶éŒ²éŸ³å¯¾å¿œ)")

# Whisperãƒ¢ãƒ‡ãƒ«é¸æŠ
model_choice = st.selectbox("Whisperãƒ¢ãƒ‡ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„", ("small", "medium"))

st.write("\nğŸ‘‰ \u9332\u97f3\u30dc\u30bf\u30f3ã‚’æŠ¼\u3057ã¦ãã‚‰ã„ã®éŸ³å£°ã‚’\u9332\u308aã¾\u3059\uff01")

# éŒ²éŸ³ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ
wav_audio_data = st_audiorec()

if isinstance(wav_audio_data, np.ndarray):
    st.success("éŒ²éŸ³å®Œäº†ï¼æ–‡å­—èµ·ã“ã—é–‹å§‹...")

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«éŒ²éŸ³ã‚’ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_wav:
        scipy.io.wavfile.write(tmp_wav.name, 44100, wav_audio_data)
        temp_audio_path = tmp_wav.name

    # Whisperãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model = whisper.load_model(model_choice)
    result = model.transcribe(temp_audio_path)

    full_text = result['text']

    # ç°¡æ˜“è¦ç´„
    summarized_text = "\n".join([line.strip() for line in full_text.split("\u3002") if len(line.strip()) > 10])

    # çµæœè¡¨ç¤º
    st.subheader("è­°äº‹éŒ²ç·æ‹¬")
    st.text_area("", value=summarized_text, height=400)

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    st.download_button(
        label="è­°äº‹éŒ²ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=summarized_text,
        file_name="meeting_summary.txt",
        mime="text/plain"
    )
else:
    st.info("éŒ²éŸ³ã¾ã ã—ã¦ã„ã¾ã›ã‚“ï¼ã€€éŒ²éŸ³ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
